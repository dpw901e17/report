\section{The Short History of Graphics \acs{API}s}\label{sec:short_history}
In this section, we describe the history of graphics programming up to and including the introduction of Direct3D 12 and Vulkan.
This is done as to place these recent developments in the context of what came before.

\subsection{Early Days of Consumer Graphics}
In the early 1980s, dedicated hardware for rendering images became available on home PCs in the form of video display controllers \cite{wikiVideoDisplayController}.
These devices were tasked with producing composite video signals to the computer’s CRT monitor.
They often did not have their own memory, instead the video RAM was shared with the \gls{CPU} as part of its memory map \cite{wikipedia????shared}.


In its most basic form, an image would be rendered on screen by having the \gls{CPU} write a bitmap to the shared memory.
A bitmap is an array containing a color value for each screen pixel.
The size of the bitmap depends on the resolution of the screen and the color depth.
Color depth refers to the range of colors a single pixel may be given in the bitmap.
A range of two colors requires one bit, four colors require two and so on.
Thus, the larger the range, the more bits are required to store the color of each pixel.


To give a concrete example of graphics programming at the time, we look at the Commodore 64 from 1984.
The rest of this subsection will be based on \citet{commodore1983commodore}.
It was originally released on the home computer market in 1984 with a total of 64 kilo bytes of memory, using the MOS Technology VIC-II graphics chip.
The chip supported a 320 by 200 pixels video resolution, 16 colors, and 16 kB memory for screen, character, and sprites.
In this context, a sprite a small bitmapped image, which can be manipulated and drawn on top of another image.

However given this setup, storing a full screen bitmap with a color depth of 4 would take
$$320\times 200\times 2 \text{ bits} = 128,000 \text{ bits} = 16,000 \text{ bytes of memory.}$$

While this bitmap can be placed in the mapped memory of the video chip, it only has two colors.
Storing a bitmap with a color depth of 16, which is what the chip can produce, would take up 32 kilo bytes.
This is equals half of the 64 kilo bytes of memory accessible to the machine, leaving little space for the memory mapped I/O and regular computations.


To output 16 color images, the Commodore 64 used a technique known as color cells, where the screen was partitioned into 40 by 25 screen segments of a limited color palette. 
The Commodore 64 had two modes for displaying color cells: High resolution mode, where all 320 by 200 pixels were usable, but with a color depth of two; and multi-color mode, where every second pixel was a repeat of the previous allowing for a color depth of four.
The latter mode was popular for games, since color was more important than resolution \cite{bogdan2014games}.


Regardless of which mode was used, the bitmap would consume 8 kB of memory and palettes would use 1 kB memory.
In high resolution mode, each segment of the bitmap was colored according to its corresponding palette.
The 0s in the bitmap segment were colored with the first color and the 1s with the second.
Using the multi-color mode, the palettes were used in the same manner, while the additional third and fourth color were defined for the entire screen.


The remaining 7 kB of memory were used for sprites.
These small bitmaps were rendered on top of the main bitmap and could be placed anywhere on screen.
hus, the main bitmap was often used for a background, while sprites were used for objects moving about on the screen.
Each sprite measured 24 by 21 pixels, allowing for 56 addressable sprites to be stored in total.
In high resolution mode, they had a color depth of 2, but in multi-color mode the lower resolution allowed for a color depth of 4.
Yet, two of these colors were common to the maximum of 8 sprites, which could be drawn on each horizontal line of pixels.
No matter the mode, one of the colors was always forced to be transparent.  

Graphics programming on the Commodore 64 was done in the BASIC programming language.
Using the PEAK and POKE commands, the programmer would read and write to the 47 graphics registers in the Commodore 64’s address range 53,248 to 53,294. 
As an example, after having defined the main bitmap and loaded sprite 0 into the mapped memory, the sprite could be written to the top left of the screen in the following manner. 


\begin{lstlisting}[caption={Small BASIC program that places sprite 0 in the top left part of the screen. }]
10 POKE 53248,0
20 POKE 53264,0
30 POKE 53249,0
40 POKE 53287,5
50 POKE 53269,1
\end{lstlisting}


Line 1 sets the first 8 bits of the x coordinate and line 2 sets the 9th bit.
This is required as only 256 values can be stored in a byte, and the screen is 320 pixels wide.
Line 3 sets the y coordinate.
Line 4 sets the local color of the sprite to green and finally line 5 shows the pixel.
Note that the top left of the screen has coordinates (0,0), as opposed to this being the location of the bottom left in most coordinate systems.
This is because the picture is drawn with scan lines that travel from left to right and start at the top of the screen for each frame. 
Thus the top left is the first part of the screen to be drawn. This is a convention that has carried over into modern graphics programming.


As can be seen, this type of graphics programming is very verbose, requiring the programmer to get close to the hardware. Yet this was how graphics programming was done before graphics \glspl{API} became prominent.

Other systems such as the Nintendo Gameboy (released in Japan in 1989) and Nintendo Entertainment System (released in Japan in 1983) used similar methods with different restrictions.
The Nintendo Gameboy supported 40 sprites, but they had to be 8 by 8 pixels, and only 10 could be on a single scanline \cite{nintendo1999gameboy}. 
The screen was also smaller, 160 by 144 pixels, and always supported four colors, that had to be the infamous four shades of green \cite{nintendo1999gameboy}.

As graphics chips became more capable and memory became larger, the full color and detail of the screen became available to the developers.
The Commodore Amiga 4000 (released in 1992) had 2 mega bytes of build-in memory and up to 12 mega bytes of additional memory.
It could also be upgraded by using the different slots.
Wolfenstein 3D simulated 3D on the \gls{CPU} and told the graphics chip the color of each individual pixel.
This was still done by writing memory addresses that the graphics chip would use when rendering to the screen.
3D accelerators did exists back then, but were mostly used in arcades, so it was not expected that the average consumer had one.

\Citet{helm1986declarative} observed that graphics processing such as the scaling done in Wolfenstein 3D would be better suited for dedicated hardware that worked in parallel. \todo{Maybe mentioned that helm was probably not the first to make this claim, and it wasn't made in regard to wolf3d}
The interface to such hardware would then receive abstractions such as vertices instead of pixels, and calculate changed pixels from those.
To program for such hardware, some sort of interface would be needed to ensure that the incoming data is well-formed.
And so, the need for graphics \glspl{API} was created.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Rise of Graphics \acs{API}s} 

In January of 1992 Silicon Graphics, Inc. released the first version of OpenGL, which tried to streamline the process of 2D and 3D graphics development \cite{segal1994opengl}.
It was based on their own proprietary graphics libary: \gls{IRIS GL}.
The first version of OpenGL was far from perfect and did not gain popularity until late 1990s when version 1.1 came out \cite{kronos????history}\todo{Source not in bib}, which introduced concepts such as vertex arrays and texture objects.
Listing \ref{lst:opengl10} is an example of an OpenGL 1.0 program using the immediate mode.
OpenGL worked as a statemachine where calls to the \gls{API} modified the state, this is very clear in the Listing \ref{lst:opengl10} on line 7 and 10 where \texttt{glBegin} and \texttt{glEnd} which tells OpenGL to prepare for some triangle data and when it is finished.

\begin{lstlisting}[language={[ANSI]C}, caption={OpenGL 1.0 program written in C, that renders a triangle with different colors on the points, and linear interpolation between the colors. This method uses the fixed pipeline to render the triangle. A method which has been deprecated since OpenGL 3.0.}, label={lst:opengl10}]
void init() {
  glClearColor(0.0f, 0.0f, 0.0f, 1.0f);
}

void draw() {
  glClear(GL_COLOR_BUFFER_BIT);
  glBegin(GL_TRIANGLES);
    glColor3f(1.0f, 0.0f, 0.0f); glVertex2f( 0.0f,  0.5f);
    glColor3f(0.0f, 1.0f, 0.0f); glVertex2f( 0.5f, -0.5f);
    glColor3f(0.0f, 0.0f, 1.0f); glVertex2f(-0.5f, -0.5f);
  glEnd();
  glFlush();
}
\end{lstlisting}

RenderMorphic tried to standardize an interface for writing games.
They called it Reality Lab, and it quickly became one of the main \glspl{API} in the graphics \gls{API} market. 
Just after a short time on the market, Microsoft bought both the company and the \gls{API} in Febuary of 1995 and it became the core for Microsoft's own 3D rendering \gls{API} \cite{1997crushed}; Direct3D.
The first version of Direct3D shipped in June 1996 with DirectX 2.0 \cite{wikipedia????directx}. 

Around the same time 3dfx's Brian Hook wrote Glide, a graphics API for the 3dfx Voodoo Graphics Accelerator \todo{Is this a GPU?}.
Because of the ease of programming to Glide, and the popularity of the Voodoo graphics accelerators, Glide became the dominating graphics \gls{API} in the late 1990's.

Glide's success was in part made possible by Microsoft's involvement in the Talisman project, which took some of resources from the DirectX team.
The Talisman project was a new 3D architechture that could reduce the memory bandwidth needed by applying tiled rendering \cite{torborg1996talisman}.
But as other 3D accelerators became more efficient and cheaper, Microsoft cancelled project Talisman and reverted their focus to Direct3D \cite{wikipedia????talisman}.
The market share of the Windows operating system gave Microsoft the consumer base that the hardware specific \glspl{API} lacked, so developers soon started to focus their attention on Direct3D.

John \citet{carmack1996plan} of Id Software critized Direct3D for being too verbose, after trying to port Quake to OpenGL and Direct3D \todo{show some opengl and direct3d code to better understand the critistism.} .
So there were some resistance to Direct3D's market dominance, so some developers insisted on using OpenGL.
And so the OpenGL and Direct3D became the dominant competitors in the 3D rendering. 

\subsection{Modern Graphics \acs{API}s}

The early days of 3D programming was still very verbose and inflexible. 
Fixed function pipelines were used, which meant you could not change how the graphics pipeline worked \cite{davidovic2014fixedfunction}.

In November 2000, Microsoft released their first version of \gls{HLSL} \todo{code example} together with DirectX 8 \cite{wikipedia????directx}.
\Gls{HLSL} is a language for small programs that runs on the \gls{GPU} instead of the \gls{CPU}.
It is designed as a high level, C-like language with extenstions to include some of the most used types such as vectors and matrices \cite{microsoft????hlsl}.
It also served as a way to decide which calculations should be performed in which render stages in the pipeline.
This introduced some flexibility to the graphics pipeline \todo{Should introduce the graphics pipeline earlier}.

OpenGL followed with their own shader language \gls{GLSL} in April 2004 \cite{wikipedia????opengl}. 
Like \gls{HLSL}, \gls{GLSL} is a C-like language with some extensions to better support operations common to graphics rendering.

\vspace{1em}

\noindent
Because OpenGL and Direct3D is in direct competition with eachother, and operate on the same hardware, once a technology, or tool has been developed for one, the other usually follows soon after.
Therefore, we look at the general graphics \gls{API} improvements in the following sections.

\vspace{1em}

\noindent
Shaders have since then been improved with more features, such as changing model details with the geometry shader, and generating model details via a tessellation stage.

The geometry shader is placed between the vertex and fragment shader and operated on primitives; points, lines, or triangles, and returned zero or more primitives for rasterizing.
Because the geometry shader could see multiple verticies at once, developers were excited for the oppotunities this would give \cite{kronos????geometry, microsoft????geometry}.
A good example of using the geometry shader is particle effects, where the specifics of the four corners of the mesh is less important for the developer than the position of the particle.
So instead, the developer can send the points of the particles to the \gls{GPU}, and have the geometry shader generate the corners in parallel.
One big issue with geometry shaders is that their performance overhead is so large that naïvely using it would often hurt performance rather than improving it.

The next change to the rendering pipeline was the introduction of a tessellation stage.
This stage involves two shaders; a hull shader and a domain shader.
It occurs after the vertex shader, but before the geometry shader.
The tessellation stage generates more details to the model by adding even more vertices.
Where the vertices are placed and how many there are, is handled by the shaders.

Later on, tessellation became the big topic, which is way to generate model details on the \gls{GPU}.
The tessellation stage is a way achieve some of the things developers imagined was possible with geometry shaders, but was not feasible because of the performance overhead the shader had.

\todo{The rest of the section could be incorporated in the section that follows.}
The most recent trend is to lower the abstraction level of the \glspl{API} to enable more customization.
This push can be seen in the most recent version of Direct3D; Direct3D 12, and the so called successor to OpenGL; Vulkan.
The lower level abstract enables the developer to customize the \gls{GPU} usage to their needs.
Removing this layer of abstraction also has the benefit of enabling multi-threaded \gls{GPU} calls, by eliminating the driver state.
The drawback is that these lower levels of abstraction are more verbose, and thus increases the complexity of even the simple task of drawing a single triangle on screen.

For instance, Figure \ref{fig:vulkan_overview} is an overview of all the components that is required to render a similar triangle to the one rendered in Listing \ref{lst:opengl11}.
The program was written by following a tutorial written by \citet{overvoorde2017vulkan}.
The resulting program was approximatly 1000 lines of code.

\fig{figures/VulkanTriangleOverview.jpg}{A diagram showing the component involved in displaying a triangle to the screen. Credits: reddit user pipsqueaker117. \todo[inline]{Lav bedre diagram når vi ved mere om vulkan.}}{vulkan_overview}{0.9}

The Vulkan implementation is far bigger than the OpenGL 1.0 version, the reason is because the Vulkan version gives more flexibility to the developer.
One feature of Vulkan is that is gets rid of the statemachine from OpenGL, because when running multi-threaded applications it is error prone to use globally shared statemachines.
