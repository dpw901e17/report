\section{The Graphics Pipeline} \label{sec:pipeline} %\todo{include working example running through all stages}
\begin{sectionmeta}
To understand the rest of the report, it is recommended to gather an understanding of what the graphics pipeline is.
The following section is based on the official documentation for graphics pipelines for Direct3D and OpenGL \cite{khronos????pipeline, microsoft????pipeline}.
It aims to give the reader a basic understanding in the stages and processes involved in the graphics pipeline.
\end{sectionmeta}

Graphics pipelines can be compared to the \gls{CPU} pipeline in the way it is a number of stages each command goes through.
Because the \gls{GPU} is based on a \gls{SIMD} architechture, the command is executed on a number of data simultaneously.
The the data is also not guranteed to be the same size from stage to stage.
For instance, a triangle can be defined by three vertices and cover many pixels, which both are input in different stages of the pipeline.

A simple pipeline can be seen in \cref{fig:pipeline02}, where a triangle is rendered using two shader programs: a vertex shader and a fragment shader.
These shaders are the variable parts of this pipeline as they can be changed if another result is desired or if the old shader programs were to slow.

\tikzfig{figures/TikZ/visual_graphics_pipeline.tex}{A simplified view of what the graphics pipeline does to the data it receives. It shows how a 32 by 32 pixel image is rendered using the vertex data and shaders. Does not include newer processing stages such as tessellation and geometry processing.}{pipeline02}

The output of the pipeline in \cref{fig:pipeline02} is just an example, the effect could be achieved using the \gls{GLSL} programs in \cref{lst:pipeline_vertex_shader,lst:pipeline_fragment_shader}, and the right vertex data input.

Lets explain what is happening in \cref{lst:pipeline_vertex_shader,lst:pipeline_fragment_shader}.
The \texttt{main} functions are the entry points for the shaders just as expected in languages such as C and C++, where \gls{GLSL} gets much of its syntax from.

The \texttt{\#version 330} line tells the \gls{GLSL} compiler that we are using version 3.3.0 of the language standard that came with OpenGL 3.3.
It must be the first line, or OpenGL will assume that we are using version 1.1.0.
The reason for this is that the keywords changed between the versions, older standards used \texttt{varying} and \texttt{attribute} instead of \texttt{out} and \texttt{in}, so the compiler needs to know which version we are targeting.

The \texttt{in} variables are the input for the shader, for the vertex shader this is the attributes in the vertex data which in this case is the position and texture coordinate. 
For the fragment shader, the input is the output of previous shader stages and we can see that the \texttt{texture\_coordinate} is coming from the vertex shader, because the names match.
The \texttt{uniform} keyword if for variables which are shared amoung the entire model, in this case it is the sampler for the texture, but can also be used for positions of light or matricies for transformations or many other things.

In OpenGL, the \texttt{gl\_Position} is the position used by the triangle assembly seen in \cref{fig:pipeline02}, and the \texttt{gl\_FragColor} is the color used for blending.

\begin{figure}[H]
\begin{lstlisting}[caption={This vertex shader takes in a position and a texture coordinate. It parses the position into the standard \texttt{gl\_Position} vector which is used internally by OpenGL. The texture coordinate is parsed through to the output and will be liniar interpolated between output from other verticies. (GLSL)},label={lst:pipeline_vertex_shader}]
#version 330
in vec3 model_position;
in vec2 model_texture_coordinate;

out vec2 texture_coordinate;

void main()
{
  texture_coordinate = model_texture_coordinate;
  gl_Position = vec4(model_position, 1.0);
}
\end{lstlisting}
\end{figure}

\begin{figure}[H]
\begin{lstlisting}[caption={This fragment shader takes a linear interpolated texture coordinate and finds the corrosponding color in a texture using a texture sampler. The sampler determine what strategy to use for super- and sub-sampling, popular strategies include linear interpolating, bilinear interpolating and nearest-neighbor. The output is then set to a standard \texttt{gl\_FragColor} vector which is used by OpenGL internally. (GLSL)}, label={lst:pipeline_fragment_shader}]
#version 330
in vec2 texture_coordinate;

uniform sampler2d texture_sampler;

void main()
{
  gl_FragColor = texture(texture_sampler, texture_coordinate);
}
\end{lstlisting}
\end{figure}

While vertex and fragment shaders are the most common types of shaders, there exist others that fit into modern graphics pipelines.
These stages are used to modify the primitives that the triangle assembly outputs, but because it is often not nesscary they are set as optional stages, and disabled per default.
Addind these stages to the pipeline seen in \cref{fig:pipeline02} results in the pipeline seen in \cref{fig:pipeline01}.


\tikzfig{figures/TikZ/graphics_pipeline.tex}{A view of the graphics pipeline. The orange boxes are fixed functions, the blue boxes with rounded corners are shaders that the developer can replace with their own programs, and the large green box is shared memory. Dashed shader stages are optional.}{pipeline01}\todo{kodeeksempler til hvert stage?}

The following paragraphs goes through the different stages in the graphics pipeline in more details, shown in \cref{fig:pipeline01}.

\paragraph{The Input Assembler} is the first stage. 
It reads the user provided data and assembles the data into structures that it sends to the next stage in the pipeline. \todo{What type of data could be provided?}
These structures include primitive types in the shader languages, such as floats, vectors, matrices, etc.

\paragraph{The Vertex Shader} is the first interchangeable stage in the pipeline \todo{what does interchangeable mean in this context?}.
Its main responsibility is to take a set of output from the Input Assembler and translate it into vertices in clip-space.
Clip-space is a space where all verticies that should be displayed are within the x and y coordinates -1 to 1 and z coordinate 0 to 1 or -1 to 1 depending on the \gls{API} \todo{why is it like this?}.
It also calculates or sets values later stages in the pipeline uses.
These values vary depending on the desired effect, but might contain color, normal vector, lighting, and/or texture coordinate.

\paragraph{The Primitive Constructor} takes the vertices and constructs primitives.
A primitive is either a point, a line, or a triangle.
Other primitives exists but are \gls{API} specific.
To enable reuse of vertices, an index buffer can be provided to tell the assembler which vertices makes a primitive.
The primitive constructor also performs the necessary clipping so off-screen vertices are not rendered.

\paragraph{The Tessellation Stage} is the first optional stage.
Its responsibility is to tessellate the primitive, which means dividing the primitive into multiple smaller primitives.
In the figure it is simplified.
The tessellation stage consists of three elements: two shader stages, and a fixed function between them.
The first shader describes how much tessellation should be done, and how.
The fixed function the generates the desired result and the last shader modifies the generated primitives.
This modification could include moving vertices according to a mathematical formula, or a texture, to show details that was otherwise not present in the model.

\paragraph{The Geometry Shader} takes in a single primitive and outputs any number of primitives.
This is used to generate particles from points, or hair and grass on surfaces.
It can also be used to mask some primitives if necessary.


\paragraph{The Rasterizer Stage} takes the primitives and calculates which fragments on the screen it covers.
Fragments in this context refers to sample-sized segments.
When rendering to the screen or texture, this will the size of a single pixel.
Rasterization might produce more than one fragment for a single pixel, depending on the parameters set, multisampling is one of such parameters.
 %to pixels either on the screen or on a target render texture.

\paragraph{The Fragment Shader} is responsible for returning the color that should be displayed on each fragment.
This stage is usually used for texture mapping, and lighting.

\paragraph{The Output Merger Stage} takes the colors from the fragment shader and blends them into the existing framebuffer. 
The framebuffer can then later be swapped for the image displayed on the screen or used as input to another pipeline.

\vspace{1em}

\noindent There are some differences in the exact implementations of the graphics pipeline in the specific \glspl{API}, but for our purpose a deeper understanding that described is not required.
Other exceptions include Vulkan, where the pipeline is entirely configurable.
Vulkan does not provide a pipeline, so the developer is free to design every aspect of how the rendering is performed. \todo{Måske flytte dette til sektionen om Vulkan?}
\todo{Et tillæg til sektionen kunne være at vise hvordan data flyder igennem stages, og visuelt vise hvordan det ændres. Fra punkter til fuzzy bunny!} 

\subsection{Geometry and Tessellation Shader}
The geometry shader is placed between the vertex and fragment shader and operated on primitives; points, lines, or triangles, and returned zero or more primitives for rasterizing.
Because the geometry shader could see multiple verticies at once, developers were excited for the oppotunities this would give \cite{kronos????geometry, microsoft????geometry}.
A good example of using the geometry shader is particle effects, where the specifics of the four corners of the mesh is less important for the developer than the position of the particle.
So instead, the developer can send the points of the particles to the \gls{GPU}, and have the geometry shader generate the corners in parallel.
One big issue with geometry shaders is that their performance overhead is so large that naïvely using it would often hurt performance rather than improving it.

The next change to the rendering pipeline was the introduction of a tessellation stage.
This stage involves two shaders; a hull shader and a domain shader.
It occurs after the vertex shader, but before the geometry shader.
The tessellation stage generates more details to the model by adding even more vertices.
Where the vertices are placed and how many there are, is handled by the shaders.

Later on, tessellation became the big topic, which is way to generate model details on the \gls{GPU}.
The tessellation stage is a way achieve some of the things developers imagined was possible with geometry shaders, but was not feasible because of the performance overhead the shader had.

After the year 2000 \glspl{GPU} began turning into massively parallel architectures, while Direct3D and OpenGL dominated the \gls{API} market. 