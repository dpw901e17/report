\section{The Graphics Pipeline} \label{sec:pipeline} \todo{include working example running through all stages}
\begin{sectionmeta}
To understand the rest of the report, it is recommended to gather an understanding of what the graphics pipeline is.
The following section is based on the official documentation for graphics pipelines for Direct3D and OpenGL \cite{khronos????pipeline, microsoft????pipeline}.
It aims to give the reader a basic understanding in the stages and processes involved in the graphics pipeline.
\end{sectionmeta}

\todo{Måske have noget med at vi bruger pipelinen som en abstraktion over at tænkte i hardware detaljer.}
\todo{This section as part of the hardware discussion? at least some talking up there about difference between pipelines.}
Graphics pipelines can be compared to the \gls{CPU} pipeline in the way it is a number of stages each command goes through.
For graphics, the command is instead\todo{instead of what?} an array of vertex data, such as position, texture coordinates, normals, and color, and unlike the \gls{CPU} pipeline, the relationship between the stages are not only one to one \todo{needs more explanation}.

\tikzfig{figures/TikZ/graphics_pipeline.tex}{A view of the graphics pipeline. The orange boxes are fixed functions, the blue boxes with rounded corners are shaders that the developer can replace with their own programs, and the large green box is shared memory. Dashed shader stages are optional.}{pipeline01}\todo{kodeeksempler til hvert stage? Er dette vores figur?}

The following paragraph goes through the different stages in the graphics pipeline, shown in \Cref{fig:pipeline01}.

\paragraph{The Input Assembler} is the first stage. 
It reads the user provided data and assembles the data into structures that it sends to the next stage in the pipeline. \todo{What type of data could be provided?}
These structures include primitive types in the shader languages, such as floats, vectors, matrices, etc.

\paragraph{The Vertex Shader} is the first interchangeable stage in the pipeline \todo{what does interchangeable mean in this context?}.
Its main responsibility is to take a set of output from the Input Assembler and translate it into vertices in clip-space.
Clip-space is a space where all verticies that should be displayed are within the x and y coordinates -1 to 1 and z coordinate 0 to 1 or -1 to 1 depending on the \gls{API} \todo{why is it like this?}.
It also calculates or sets values later stages in the pipeline uses.
These values vary depending on the desired effect, but might contain color, normal vector, lighting, and/or texture coordinate.

\paragraph{The Primitive Constructor} takes the vertices and constructs primitives.
A primitive is either a point, a line, or a triangle.
Other primitives exists but are \gls{API} specific.
To enable reuse of vertices, an index buffer can be provided to tell the assembler which vertices makes a primitive.
The primitive constructor also performs the necessary clipping so off-screen vertices are not rendered.

\paragraph{The Tessellation Stage} is the first optional stage.
Its responsibility is to tessellate the primitive, which means dividing the primitive into multiple smaller primitives.
In the figure it is simplified.
The tessellation stage consists of three elements: two shader stages, and a fixed function between them.
The first shader describes how much tessellation should be done, and how.
The fixed function the generates the desired result and the last shader modifies the generated primitives.
This modification could include moving vertices according to a mathematical formula, or a texture, to show details that was otherwise not present in the model.

\paragraph{The Geometry Shader} takes in a single primitive and outputs any number of primitives.
This is used to generate particles from points, or hair and grass on surfaces.
It can also be used to mask some primitives if necessary.


\paragraph{The Rasterizer Stage} takes the primitives and calculates which fragments on the screen it covers.
Fragments in this context refers to sample-sized segments.
When rendering to the screen or texture, this will the size of a single pixel.
Rasterization might produce more than one fragment for a single pixel, depending on the parameters set, multisampling is one of such parameters.
 %to pixels either on the screen or on a target render texture.

\paragraph{The Fragment Shader} is responsible for returning the color that should be displayed on each fragment.
This stage is usually used for texture mapping, and lighting.

\paragraph{The Output Merger Stage} takes the colors from the fragment shader and blends them into the existing framebuffer. 
The framebuffer can then later be swapped for the image displayed on the screen or used as input to another pipeline.

\vspace{1em}

\noindent There are some differences in the exact implementations of the graphics pipeline in the specific \glspl{API}, but for our purpose a deeper understanding that described is not required.
Other exceptions include Vulkan, where the pipeline is entirely configurable.
Vulkan does not provide a pipeline, so the developer is free to design every aspect of how the rendering is performed. \todo{Måske flytte dette til sektionen om Vulkan?}
\todo{Et tillæg til sektionen kunne være at vise hvordan data flyder igennem stages, og visuelt vise hvordan det ændres. Fra punkter til fuzzy bunny!} 

\subsection{Geometry and Tessellation Shader}
The geometry shader is placed between the vertex and fragment shader and operated on primitives; points, lines, or triangles, and returned zero or more primitives for rasterizing.
Because the geometry shader could see multiple verticies at once, developers were excited for the oppotunities this would give \cite{kronos????geometry, microsoft????geometry}.
A good example of using the geometry shader is particle effects, where the specifics of the four corners of the mesh is less important for the developer than the position of the particle.
So instead, the developer can send the points of the particles to the \gls{GPU}, and have the geometry shader generate the corners in parallel.
One big issue with geometry shaders is that their performance overhead is so large that naïvely using it would often hurt performance rather than improving it.

The next change to the rendering pipeline was the introduction of a tessellation stage.
This stage involves two shaders; a hull shader and a domain shader.
It occurs after the vertex shader, but before the geometry shader.
The tessellation stage generates more details to the model by adding even more vertices.
Where the vertices are placed and how many there are, is handled by the shaders.

Later on, tessellation became the big topic, which is way to generate model details on the \gls{GPU}.
The tessellation stage is a way achieve some of the things developers imagined was possible with geometry shaders, but was not feasible because of the performance overhead the shader had.

After the year 2000 \glspl{GPU} began turning into massively parallel architectures, while Direct3D and OpenGL dominated the \gls{API} market. 