\section{Related Works}\label{sec:related_works}
\begin{sectionmeta}
This section will describe the related works within this project.
From these papers it was discovered that a \gls{GPU} is used for two kinds of operation: 
The first purpose for the \gls{GPU} is for rendering graphics, this is used in video games, video rendering and overall graphical visualization in any kind of application. 
Secondly as a GP\gls{GPU}, meaning using the \gls{GPU} for general purpose programing and utilizing its massive parallelism.
The following sections will further explain the related works, and why they are relevant.
\end{sectionmeta}

Having now listed some background knowledge about graphics programming and the role of graphics \glspl{API}, the final section of this chapter will discuss works related to our own.
This is done as to place our own work in an academeic context, and introduce the landscape of current publications. 

\subsection{Graphics}
This section will describe how \glspl{GPU} are used in terms of rendering graphics, and elaborate on what kind of issues that can be encountered whilst working with rendering graphics.

\vspace{1em}

\subsubsection{Let's Fix OpenGL}

\citet{fix_opengl} attempts to expose the shortcommings of OpenGL, and suggests research topics to improve the \gls{API}. 
The issues mentioned also applies to Direct3D according to the author. 
He identifies six issues: 

\begin{enumerate}
\item Programmers must juggle between C/C++ and \gls{HLSL} and \gls{GLSL}.
Meaning they have to switch between coding the renderer in a general purpose language and coding the shaders in a shader language.

\item The communication between \gls{CPU} and \gls{GPU} is brittle. 
They communicate to share data through commands written in the application, there is no way to statically check if the variable name in the application and shader match.
This is a error-prone approach, as such bugs can first be found during runtime of the application. 
\todo{This point is a bit vauge. What communication are we talking about?}

\item Massive meta-programming. 
There can be generated thousands of varients of a shader program, this is not good as it comes at a performance cost \todo{what type of variants?}. 
\todo{We always have to write a lot of shaders, the problem is that there's no support for scaling up}

\item Different semantics for each shader stage. 
This contributes to the issue of having to keep track of semantics depending on what kind of shader is being worked on.
\todo{Give an example of how semantics are mismatched}
It makes it more difficult to use OpenGL, and increases the learning curve. 

\item No type system for vectors when converting between spaces. 
\todo{We have to remember to talk about spaces}
It has to be done manually, it should be possible to simply standardize such an approach.

\item Diffcult to verify correctness of a graphics application. 
There is no way to test whether whatever an application renders, is the actual desired result.
\end{enumerate}

In the conclusion, the article mentions Vulkan and that it might be the solution to some of the issues in OpenGL. 
Additionally, it also encourages development of new frameworks to rival OpenGL. 
However a shortcomming of the article is that all the listed issues is only based on the authors opinion that he has discussed with his collegues, and not used a proper methodology to collect this data. 
Although they do reveal that OpenGL is not a \gls{API} without flaws.

The value of this article is that it gives insight as to how a good graphics \gls{API} should work.
These are good arguments to take into consideration when trying to evaluate an \gls{API}.

\subsubsection{An Incremental Rendering VM} \todo{The main thing to take away from here is that render order is important, and that building on top of OpenGL is an option. This should perhaps be more clear.}

\noindent \citet{haaser_2015_incremental} suggest a new way of looking at rendering. 
They observe that most of the graphics and associated draw commands used for rendering one frame, can be reused for the next frame with great likelihood.

To use this knowledge they develop a high-level abstraction over the draw calls where the render task are organized using a trie, where each leaf is a render state and a bucket of render objects. \todo{Maybe add a picture of the trie?}
Objects in the same bucket can be rendered without switching between render states.

The program takes this trie and compiles it into virtual machine code, that is translated into OpenGL draw calls.
The translated OpenGL code is kept between frames, to avoid compiling unchanged code.
In other words, this is a just-in-time compilation.

The advantage they get from using virtual machine code as an intermediate representation, is that they can do some optimization before translating to OpenGL draw-calls.
This optimization only has to be performed once for every change in the render task.
And they defragment the representation to reduce cache misses, which increases performance even further. \todo{Do we need this level of detail?}

When changes occur in the picture to be rendered, they group the change into two types: incremental changes and structural changes.
Incremental changes to a render object, such as changing the color or the entire shader, is handled by moving the object between buckets.
Structural changes, such as removing and adding render objects to the scene, is handled by adding or removing objects to or from the buckets.
This moving, adding and removing rendering objects makes the defragmentation vital to ensure performance equal to other rendering methods.

They show in benchmarks that the overhead the virtual machine introduces are negligible, and that rendering speed depended on the size of the change being applied. \todo{Need something about how we can build a more abstract API on top of this}

\subsection{Comparison} \todo{Find out whether to refer to authors directly as he/she}
There are several options in terms of what \gls{GPU} \gls{API} that can be used when a developer needs to render graphics in an application.
This subsection discusses articles that compare \gls{GPU} \glspl{API} against one another, and why and when certain \glspl{API} should be chosen over others.
These papers present work similar to ours.

\subsubsection{Direct3D 11 vs 12 A Performance Comparison Using Basic Geometry}

\citet{2016_direct3d} wrote an intresting\todo{that's a loaded word. Don't add loaded words like this.} article as part of his masters thesis, where he compared Direct3D 11 and 12, and found that Direct3D 11 performed better than Direct3D 12.
The test were a scene with a number of points where each point has a fixed color.
Performance is measured as the number of points to be rendered is increased.

The results he got contradicts other benchmarks and he used the discussion to reflect on why.
In the discussion he reflects over the implementation, where the Direct3D 12 implementation is modeled after the Direct3D 11 implementation to ensure that it is the \gls{API} implementation that affects the performance and not the newer features.
This might have been a mistake because he could not use Direct3D 12 to its fullest extent, as he could with Direct3D 11.

He does notice that Direct3D 12 uses less \gls{CPU} time and fewer threads, and theorises that Direct3D 11 does a lot of optimization where Direct3D 12 lets the developer handle optimization.
The paper ends with the author stating that if the features of Direct3D 12 were better used, it would possibly get better performance than Direct3D 11. \todo{Maybe have a line about how we strive to make a more fair comparison in light of this}

\subsubsection{Reducing Driver Overhead in OpenGL, Direct3D and Mantle}

\citet{dobersberger_2015_reducing} covered three different graphics \gls{API} as part of his master thesis. 
He looked at the different ways the \glspl{API} enable the developer to reduce the overhead of using their \gls{API}. 
He then uses that knowledge to conclude something about the individual \glspl{API} such as; Direct3D focuses on multithreaded rendering, and Mantle's low-level api reduces \gls{CPU} usage and memory overhead.

Because Mantle is not released to the public, only OpenGL and Direct3D 11 are compared.
They are compared by targeting some of the features described in the specific \gls{API} sections,\todo{What sections? Ours or his?} and mesuring the performance when using the feature and when ignoring them.
If there exist comparable features in both \glspl{API}, then the performance tests are grouped together, to compare the different approaches to the problem.
In some cases, the results are verified by using third party \gls{API} tests.

The final conclusion states that overhead \glspl{API} introduces is significant, and that developers should be aware of the trade-off they make when using one feature over another.
Often the trade-off is flexibility for performance.
The author is optimistic about Vulkan and Direct3D 12, as some of the features proposed are gonna reduce the overhead.

It is releavant to this project \todo{vend det med de andre om vi kalder det et projekt} since both Vulkan and Direct3D 12 tries to reduce the \gls{API} overhead.
One way that this tries to achive this is by making the developer responsible for defining the pipeline.
We could continue his work by comparing specific features of Vulkan and Direct3D 12 on how they work and how much they reduce the \gls{API} overhead, if at all.

\subsubsection{Evaluation of multi-threading in Vulkan}

Evaluation of multi-threading in Vulkan \cite{blackert_2016_evaluation} is a master thesis that attempts at evaluating the multi-threading performance of Vulkan. It does so by comparing it to its predescor; OpenGL. 
Additionally it also evaluates the programmability of Vulkan. 

In the conclusion, the thesis states that Vulkan can give more throughput than OpenGL. \todo{A bit weird how we go in a lot of detail with other papers, while this is described in a rather short form. Perhaps find a middleground in detail and stick with it.}
Not all applications will gain a significant performance boost with using Vulkan over OpenGL. 
This would be in cases where multi-threading is not needed, or if the application is not CPU bound. 
No methodology was used in evaluating the programmability of Vulkan, it is based on the personal experience of the author, which is not a good enough method to evaluate an \gls{API} on. 
It only states that Vulkan is more difficult to work with than OpenGL, because there is more overhead since Vulkan is at a lower abstraction level than OpenGL. 

For future work the thesis encourages to further evaluate the performance of Vulkan multi-threading  capabilities by comparing it to Direct3D 12, and testing the portability of Vulkan on various operating systems and different \gls{GPU} manufactoreres.
\todo{Should we do a critique of them comparing very different APIs?}

\subsection{\gls{GPGPU}}
This section will describe related work as to what GP\gls{GPU} are, what they are used for, and how they relate to the project.

Designing efficient sorting algorithms for Manycore \glspl{GPU} \cite{satish_2009_designing} is an article which describes the development of a custom implemented radix sort and a merge sort, and prove the capabilites of CUDA and \glspl{GPGPU} parallarism, by running several Nvidia \glspl{GPU} for comparrison. 
This article demonstrates how much throughput there is to be gained from \glspl{GPGPU}, and how a comparison can be done. 
A critique of the paper though is that mege sort and radix sort starts to show strange performance spike patterns when working with large workload. 
This is never explained as to why, it should have been elaborated or at the least given a guess.
The article demonstrates how powerful the \gls{GPU} is when it is able to do some things better than a \glspl{CPU}.

The GPU Computing Era \cite{gpu_computing_era} is an article, which discusses the benefits of utilizing \gls{GPU} parallarism to run applications that previously were deemed too time consuming to use in practice. 
The article claims that single-threaded applications no longer perform well enough up against multi-threaded applications, and the industry should adapt to GP\gls{GPU} technology. 
It also mentions, how the \gls{GPU} becomes more powerful all the time by doubling up on its transistors for every 18th month. 
One way of utilizing \gls{GPGPU} is through CUDA. (Nvidia implementation of a gls{GPGPU} gls{API}.)
CUDA programs are very scalable according to the article, and it is thus an excellent tool to utilize \gls{GPGPU} functionality, and encourages more ussage of \gls{GPGPU}.
It is important to note that the authors of this article are from Nvidia, and they are likely biased towards how much power a \gls{GPGPU} can provide, and how good CUDA is. 

This article is revevant as it shows an alternative use of the \gls{GPU}, it is also explains how it achieves the parallarism which contributes to a better \gls{GPU} throughput than a \gls{CPU} can provide.

There have been made a number of tools in order to make utilization of GPGU easier, these Higher Level GP\gls{GPU}'s tool includes the following: Firepile (Scala) \cite{2011_firepile}, OCaml GP\gls{GPU} \cite{bourgoin_2017_high}, PyCuda and PyOpenCL \cite{2012_pycuda_pyopencl} and Chestnut \cite{stromme_2012_chestnut}.
It is important to mention that these \glspl{API} are only some of the tools that provide higher abstraction level GPGPU programming. 
Additionally these tools are mostly academeic experiements.

These tools were made in order to make it easier and less error prone to utilize GP\gls{GPU} for less skilled developers.
As it can be difficult to work with the low level \gls{API} (eg. CUDA).
The value in these articles lies in how the developers expose lower level \glspl{API} to a custom made higher level \gls{API}, and whether or not they are easier to use than their lower-level counterparts. 
Addtionally, it is also interesting to see how well these higher level abstraction compare performance-wise to the lower level ones. 
However, a pitfall the four papers has is that they do not have a proper methodology to test out the programmability of these \glspl{API}, which is highly desired when the goal of these tools is to be easier and more intuitive to use than their lower-level counterparts.
The articles attempts to show the programmability of their \glspl{API} by exemplifying what kind of issues their \gls{API} can solve, the syntax of using the \gls{API} and sometimes with a performance evaulation.
However it all comes down to just the authors opinion.

Debunking the 100x \gls{GPU} vs. \gls{CPU} Myth \cite{lee_2010_debunking} claims that GP\glspl{GPU} are not that much better than \glspl{CPU}. 
It references several papers that claim \glspl{GPU} can be 100 (or more) times better than a \gls{CPU}, and attempts to debunk them. 
With the data that the article collects it concludes that \glspl{GPU} are only 2x times better on average than the \glspl{CPU}. 
The testing was done by writing several algorithms and implement them for both the \gls{GPU} and \gls{CPU}, running the algorithms, observing the performance, and then comparing the results. 
However the \gls{CPU} implementation is highly optimized as the authors and software writers are from Intel, whilst the GP\gls{GPU} implementation for the algorithms is not optimized to its fullest. 
Data from an article like this would have been more meaningful if the GP\gls{GPU} implementation was written some of the best people from Nvidia (since they tested with a Nvidia card) instead of someone from Intel.

\paragraph{}
From these sources it is possible to form a better overview of what is currently going on in the area of \glspl{GPU} in the scientific community. 
Based on these sources, it can be concluded that not many articles are looking into the programmability of \gls{GPU} \glspl{API}. 
The thesis papers were the only once that made an attempt at evaluating Vulkan and DirectX12.

Aditionally there seems to be a lack on papers discussing Direct3D 12 and Vulkan, and should therefore be considered a field that is worthwhile looking into.
